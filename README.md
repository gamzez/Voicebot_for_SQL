# Voice controlled ChatGPT via speech-to-text transcription
Demo video:

[![DEMO VIDEO](https://img.youtube.com/vi/RtHqt6pTdGw.jpg)](https://youtu.be/RtHqt6pTdGw)

This is a voice-controlled SQL query generator powered by AI models from OpenAI.
The script uses OpenAI's Whisper model to transcribe voice input into text. The transcribed text is then passed to ChatGPT via OpenAI API; GPT is asked to generate a SQL code for given query task. 
In other words:
speech --> ChatGPT --> SQL query



To install dependencies you can run the requirements file:

 ```
 pip install -r requirements.txt
 ```


In order to use Whisper, it is necessary to have the command-line tool [`ffmpeg`](https://ffmpeg.org/) installed on your system. You can typically install ffmpeg through most package managers:
```
# on Ubuntu or Debian
sudo apt update && sudo apt install ffmpeg

# on Arch Linux
sudo pacman -S ffmpeg

# on MacOS using Homebrew (https://brew.sh/)
brew install ffmpeg

# on Windows using Chocolatey (https://chocolatey.org/)
choco install ffmpeg

# on Windows using Scoop (https://scoop.sh/)
scoop install ffmpeg
```

## ChatGPT API

Generate an API key from your OpenAI account to use ChatGPT API. Enter your key into the file named openai_api_key.txt.
Check out the Medium article for more information:
[ChatGPT-API](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)


## Whisper

Whisper is an open-source speech recognition and translation model generated by OpenAI. It is a tool that understands spoken words from different languages.

In the script, the user's speech command is transcribed using the Whisper model and then transcribed text is passed into ChatGPT.

You can check the Whisper GitHub page for further information:
[Whisper](https://github.com/openai/whisper)

## Command-line usage
While executing the script, you have arguments "model" and "timeout". The "model" parameter offers five sizes: "tiny", "base", "small", "medium", and "large". 
Considering the requirements of this task, it is recommended to use the "tiny" model since it provides both high speed and enough accuracy. 

Additionally, you can set the "timeout" parameter, after which the code stops listening and provides the transcribed speech text and its response.

Example usage:

```  python voicebot_demo.py --model tiny --timeout 3.5 ```


